% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bertopic.R
\name{online_count_vectorizer}
\alias{online_count_vectorizer}
\title{An online variant of the CountVectorizer with updating vocabulary.}
\usage{
online_count_vectorizer(decay = NULL, delete_min_df = NULL, ...)
}
\arguments{
\item{decay}{A value between [0, 1] to weight the percentage of frequencies the previous bag-of-words should be decreased. For example, a value of .1 will decrease the frequencies in the bag-of-words matrix with 10% at each iteration.  Default `NULL`}

\item{delete_min_df}{Delete words eat each iteration from its vocabulary that do not exceed a minimum frequency. This will keep the resulting bag-of-words matrix small such that it does not explode in size with increasing vocabulary. If decay is None then this equals min_df. Default `NULL`}

\item{...}{Other parameters     inherited from: sklearn.feature_extraction.text.CountVectorizer In practice, this means that you can still use parameters from the original CountVectorizer, like stop_words and ngram_range.}
}
\description{
An online variant of the CountVectorizer with updating vocabulary.
}
\examples{
library(bertopic)
online_count_vectorizer()
obj <- online_count_vectorizer(stop_words="english")
obj

}
